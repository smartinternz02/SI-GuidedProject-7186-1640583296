{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7cae7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Found\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "if tf.test.gpu_device_name():\n",
    "    print(\"GPU Found\")\n",
    "else:\n",
    "    print(\"Not Found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c15a7bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Rated 4.0', 'RATED\\n  A beautiful place to dine in.The interiors take you back to the Mughal era. The lightings are just perfect.We went there on the occasion of Christmas and so they had only limited items available. But the taste and service was not compromised at all.The only complaint is that the breads could have been better.Would surely like to come here again.'), ('Rated 4.0', 'RATED\\n  I was here for dinner with my family on a weekday. The restaurant was completely empty. Ambience is good with some good old hindi music. Seating arrangement are good too. We ordered masala papad, panner and baby corn starters, lemon and corrionder soup, butter roti, olive and chilli paratha. Food was fresh and good, service is good too. Good for family hangout.\\nCheers'), ('Rated 2.0', 'RATED\\n  Its a restaurant near to Banashankari BDA. Me along with few of my office friends visited to have buffet but unfortunately they only provide veg buffet. On inquiring they said this place is mostly visited by vegetarians. Anyways we ordered ala carte items which took ages to come. Food was ok ok. Definitely not visiting anymore.'), ('Rated 4.0', 'RATED\\n  We went here on a weekend and one of us had the buffet while two of us took Ala Carte. Firstly the ambience and service of this place is great! The buffet had a lot of items and the good was good. We had a Pumpkin Halwa intm the dessert which was amazing. Must try! The kulchas are great here. Cheers!'), ('Rated 5.0', 'RATED\\n  The best thing about the place is itÃ\\x83Ã\\x83Ã\\x82Ã\\x82Ã\\x83Ã\\x82Ã\\x82Ã\\x92s ambiance. Second best thing was yummy ? food. We try buffet and buffet food was not disappointed us.\\nTest ?. ?? ?? ?? ?? ??\\nQuality ?. ??????????.\\nService: Staff was very professional and friendly.\\n\\nOverall experience was excellent.\\n\\nsubirmajumder85.wixsite.com'), ('Rated 5.0', 'RATED\\n  Great food and pleasant ambience. Expensive but Coll place to chill and relax......\\n\\nService is really very very good and friendly staff...\\n\\nFood : 5/5\\nService : 5/5\\nAmbience :5/5\\nOverall :5/5'), ('Rated 4.0', 'RATED\\n  Good ambience with tasty food.\\nCheese chilli paratha with Bhutta palak methi curry is a good combo.\\nLemon Chicken in the starters is a must try item.\\nEgg fried rice was also quite tasty.\\nIn the mocktails, recommend \"Alice in Junoon\". Do not miss it.'), ('Rated 4.0', 'RATED\\n  You canÃ\\x83Ã\\x83Ã\\x82Ã\\x82Ã\\x83Ã\\x82Ã\\x82Ã\\x92t go wrong with Jalsa. Never been a fan of their buffet and thus always order alacarteÃ\\x83Ã\\x83Ã\\x82Ã\\x82Ã\\x83Ã\\x82Ã\\x82Ã\\x92. Service at times can be on the slower side but food is worth the wait.'), ('Rated 5.0', 'RATED\\n  Overdelighted by the service and food provided at this place. A royal and ethnic atmosphere builds a strong essence of being in India and also the quality and taste of food is truly authentic. I would totally recommend to visit this place once.'), ('Rated 4.0', 'RATED\\n  The place is nice and comfortable. Food wise all jalea outlets maintain a good standard. The soya chaap was a standout dish. Clearly one of trademark dish as per me and a must try.\\n\\nThe only concern is the parking. It very congested and limited to just 5cars. The basement parking is very steep and makes it cumbersome'), ('Rated 4.0', 'RATED\\n  The place is nice and comfortable. Food wise all jalea outlets maintain a good standard. The soya chaap was a standout dish. Clearly one of trademark dish as per me and a must try.\\n\\nThe only concern is the parking. It very congested and limited to just 5cars. The basement parking is very steep and makes it cumbersome'), ('Rated 4.0', 'RATED\\n  The place is nice and comfortable. Food wise all jalea outlets maintain a good standard. The soya chaap was a standout dish. Clearly one of trademark dish as per me and a must try.\\n\\nThe only concern is the parking. It very congested and limited to just 5cars. The basement parking is very steep and makes it cumbersome')]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\"zomato.csv\")\n",
    "data_review = dataset['reviews_list']\n",
    "\n",
    "print(dataset['reviews_list'][0])\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for row_num in range(0,51717):\n",
    "    lst = data_review[row_num].split(\"('\")\n",
    "    for i in lst:\n",
    "        if len(i) > 5:\n",
    "            if i.find(\"',\") != -1:\n",
    "                single_rev = i.split(\"',\")\n",
    "                if len(single_rev[0]) > 2:\n",
    "                    x.append(single_rev[0])\n",
    "                if len(single_rev[1]) > 2:    \n",
    "                    y.append(single_rev[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c222edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10e4ec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "rating_final = []\n",
    "review_final = []\n",
    "\n",
    "for loop in range(0,40000):\n",
    "    data_x = x[loop]\n",
    "    data_x = re.sub('[a-zA-Z]', \" \", data_x)\n",
    "    data_x = data_x.split()\n",
    "    data_x = ''.join(data_x)\n",
    "    data_x = float(data_x)\n",
    "    if data_x < 2.5:\n",
    "        rating_final.append(\"poor\") #poor\n",
    "    elif data_x >= 2.5 and data_x <= 3.5 :    \n",
    "        rating_final.append(\"average\") # average\n",
    "    elif data_x > 3.5:\n",
    "        rating_final.append(\"good\") #good\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67abf480",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "rating_final = le.fit_transform(rating_final)\n",
    "\n",
    "rating_final = np.array(rating_final)\n",
    "rating_final = np.expand_dims(rating_final, axis=1)\n",
    "        \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "one = OneHotEncoder()\n",
    "rates = one.fit_transform(rating_final).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdd03411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       ...,\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e904df31",
   "metadata": {},
   "outputs": [],
   "source": [
    "for loop in range(0,40000) : \n",
    "    data_y = y[loop]\n",
    "    data_y = re.sub('[^a-zA-Z]', \" \", data_y)\n",
    "    data_y = data_y.lower()\n",
    "    data_y = data_y.split()\n",
    "    data_y = [ps.stem(word) for word in data_y if not word in set(stopwords.words('english'))]\n",
    "    data_y = ' '.join(data_y)\n",
    "    review_final.append(data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc2553ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features = 20000, dtype= np.float32)\n",
    "x_final = cv.fit_transform(review_final).toarray()\n",
    "\n",
    "import pickle\n",
    "pickle.dump(cv, open('cv.pkl','wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02fa499c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_final,rates, test_size = 0.2, random_state = 0)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f88c0df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data= tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
    "test_data= tf.data.Dataset.from_tensor_slices((x_test,y_test))\n",
    "\n",
    "train_dataset= train_data.batch(64).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset= test_data.batch(64).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "013dcbc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None, 13264), (None, 3)), types: (tf.float32, tf.float64)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5145c209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "500/500 [==============================] - 3s 4ms/step - loss: 0.4668 - accuracy: 0.8152 - val_loss: 0.3051 - val_accuracy: 0.8931\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.1916 - accuracy: 0.9326 - val_loss: 0.2721 - val_accuracy: 0.9170\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.1106 - accuracy: 0.9624 - val_loss: 0.3351 - val_accuracy: 0.9262\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.0911 - accuracy: 0.9696 - val_loss: 0.3651 - val_accuracy: 0.9304\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.0856 - accuracy: 0.9709 - val_loss: 0.3796 - val_accuracy: 0.9295\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.0894 - accuracy: 0.9706 - val_loss: 0.3671 - val_accuracy: 0.9312\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.0803 - accuracy: 0.9736 - val_loss: 0.4108 - val_accuracy: 0.9254\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.0801 - accuracy: 0.9732 - val_loss: 0.4164 - val_accuracy: 0.9270\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.0736 - accuracy: 0.9747 - val_loss: 0.4578 - val_accuracy: 0.9308\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.0718 - accuracy: 0.9751 - val_loss: 0.4734 - val_accuracy: 0.9305\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b3ecd5bee0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(units = 128,activation = 'relu'))\n",
    "model.add(Dense(units = 128,activation = 'relu'))\n",
    "model.add(Dense(units = 64,activation = 'relu'))\n",
    "model.add(Dense(units = 32,activation = 'relu'))\n",
    "model.add(Dense(units = 3, activation = 'softmax'))\n",
    "model.compile(optimizer = 'adam',loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(train_dataset,epochs = 10, validation_data = test_dataset, steps_per_epoch=len(train_dataset), \n",
    "          validation_steps= len(test_dataset))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57eec4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "# model=tf.keras.models.load_model('zomato_2_analysis.h5')\n",
    "\n",
    "text =  \"The food was really very bad. The ambiance was poor everyone disliked the place, the staff were very unfriendly.\"\n",
    "text = re.sub('[^a-zA-Z]', ' ',text)\n",
    "text = text.lower()\n",
    "text = text.split()\n",
    "text = [ps.stem(word) for word in text if not word in set(stopwords.words('english'))]\n",
    "text = ' '.join(text)\n",
    "\n",
    "y_p = model.predict(cv.transform([text]))\n",
    "\n",
    "alst=['poor','average','good']\n",
    "\n",
    "print(alst[tf.argmax(y_p[0], axis= 0)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
